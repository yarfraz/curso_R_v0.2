---
title: "Clase_3"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

# Fases del analisis de datos 


# **SETUP INICIAL** 

## Working Directory 

```{r}
setwd("~/github/Curso_R/")
```


## Paquetes


```{r message=FALSE, warning=FALSE}
library(readr)
library(dplyr)
library(visdat)
library(psych)
library(DescTools)
```


## Importar datos
En R se pueden importar muchos tipos de datos. Desde archivos excel hasta imagenes un png. 
Para este curso nos interesa especificamente 2 tipos de archivos: CSV y EXCEL, por ser los mas comunes.

Con la funcion read_csv() podemos leer los datos del formato .csv (comma separated values). Es necesario que coloques la direccion del archivo en tu pc entre comillas. Esta funcion les muestra informacion descriptiva sobre el dataset.

```{r}
df_rrhh <- read_csv("~/github/Curso_R/Clase_3/rrhh_datos.csv") 
```

Pero tambien puedes importar tus datos desde la interfaz. Para eso sigue los siguientes pasos:

1. Ve a la parte superior derecha y busca el icono que dice "Import Dataset"
2. Al presionarlo aparecera una lista desplegable con los formatos de dataset que R puede leer.
3. Elige el formato que corresponda con tu dataset. El formato "From Text (readr)" corresponde a CSV con el paquete readr. Usar este preferiblemente
4. Al hacer click en un formato se abrira una pestaña en la que podras elegir y visualizar tu data 
5. Clickea "Browse" para buscar tu data en tus archivos. 
6. Selecciona tu archivo y luego veras un previsualizacion de la dato.
8. Dale "Import" en la parte inferior derecha. Listo. R correra el codigo para subir la data.
7. Opcional: puedes editar con las opciones disponibles para manipular alguna informacion de tus datos. Esto en caso que quieras cambiar la clase de alguna columna, entre otras cosas. 

## Exploracion inicial

Nos permite entender como estan estructurados los datos con los que vamos a trabajar. Luego de entender su estructura y contenidos podemos planificar que se necesita hacer con estos datos

### 1. Pueden hacer click en la data en el enviroment para verla
Esto permite ver los datos como si fuera una hoja de excel. Es la forma manual de ver los contenidos de sus datos. Puede ser util si tienes una data con pocas filas y columnas. De lo contrario, no tiene sentido. 

### 2. Pueden usar funciones para ver partes de sus datos
Hay diversas funciones disponibles para hacer esto.
Las mas comunes son:

#### **spec()**
Viene integrado con el paquete **readr**. Les permite ver el nombre y la clase de todas las columnas.
```{r}
spec(df_rrhh)

```

#### **head()**
Les permite ver las primeras filas de un dataframe:
```{r}
head(df_rrhh)


```
Tiene un argumento que permite indicarle cuantas filas mostrar:
```{r}
head(df_rrhh, 2)


```

  
#### **tail()**
Permite ver las ultimas filas del dataframe. Al igual que head() tambien puedes indicarle el numero de filas que quieres ver 
```{r}
tail(df_rrhh, 10)
```

#### **Summary()** 
Permite hacer algunas observaciones y calculos estadisticos sobre las variables de nuestra data. 

Para variables numericas nos muestra: 

* Valor minimo
* 1er cuantil (el valor que se encuentra al 25% de la distribucion)
* La mediana
* La media aritmetica
* 3er cuantil (el valor que se encuentra al 75% de la distribucion)
* Valor maximo
* Cantidad de datos ausentes (NA)

Para variables de tipo factor nos muestra las categorias y su cantidad.
```{r}
summary(df_rrhh)
```

#### **glimpse()**
Es la version del paquete dplyr para observar los datos. Te da la siguiente informacion del dataset:

* Numero de filas 
* Numero de columnas
* Nombre de cada variable (columna), su clase y una muestra de sus contenido
```{r}
glimpse(df_rrhh)
```


#### Visualizar datos ausentes (NA)
Revisar los NA de tus datos es un deber. Para eso utilizaremos una funcion del paquete **visdat**. 

La funcion *vis_miss()* proyecta un visualizacion de los datos en la que señala en gris oscuro los datos NA. Esto sirve para tener una imagen de los datos ausentes de nuestros datos 

```{r}
vis_miss(df_rrhh)
```

Que puedes entender del grafico?

Que crees que deberiamos hacer?

## Limpieza de los datos
Necesitamos tener la data limpia para poder trabajar con ella. Pero que significa que este limpia?

* Que cada variable de nuestros datos este representada en una columna
* Que cada unidad de informacion represente una fila
* Que los datos se puedan observar en el formato de una tabla
* Que no existan datos ausentes 
* Que los datos de las columnas no tengan datos extraños



### Cambiar nombre a las columnas
Existen varias conveciones sobre como deben nombrarse las objetos en R. Siempre hay que ser descriptivos con nuestro codigo. Por eso lo mas razonable es ponerle nombres claros y concisos a los objetos que creamos. Pero esto implica tambien que no podemos extendernos mucho. 

R tiene varias guias de estilo. A lo largo del curso hemos utilizado _The Tidyverse Style Guide_ (https://style.tidyverse.org/syntax.html). 
De acuerdo a esta guia, los nombres deben tener el siguiente formato:

* Texto en minuscula
* Los espacios deben ser remplazados con "_" 

Con este formato vamos a cambiar los nombres de las variables del dataset utlizando la funcion **rename** de dplyr.

Para usar esta funcion se escribe: _nombre modificado_ = _nombre actual_

```{r}
df_rrhh <- df_rrhh %>% # asignamos el cambio a la data y utilizamos el pipe operator 
  rename(
   emp_name = Employee_Name, # puede abreviarse
   emp_id = EmpID,
   po_id = PositionID,
   po_name = Position,
   us_state = State, # mas descriptivo
   age = Age,
   sex = Sex,
   marital_status = MaritalDesc, # mas descriptivo
   citizenship = CitizenDesc,
   latino = HispanicLatino,
   race = RaceDesc, # mas corto
   hire_date = DateofHire,
   term_date = DateofTermination,
   term_reason = TermReason,
   employment_status = EmploymentStatus, # mas largo pero mas descriptivo
   department = Department,
   manager_name = ManagerName,
   manager_id = ManagerID,
   recruitment_source = RecruitmentSource,
   performance_score = PerformanceScore,
   engagement_survey = EngagementSurvey,
   emp_satisfaction = EmpSatisfaction,
   special_proj_count = SpecialProjectsCount,
   last_perf_rev_date = LastPerformanceReview_Date,
   days_late_last_30 = DaysLateLast30,
   absences = Absences
   
  )


```

Ejecutamos glimpse para ver los cambios
```{r}

glimpse(df_rrhh)
```


Una vez hayamos cambiado los nombres. Tendremos 1 de las 5 condiciones para tener una tidy data.

### Enfrentar los NA
Como ya vimos, nuestra data tiene varios NA regados en su interior. Debemos tratar estos NA por las siguientes razones>

* Algunas funciones pueden verse afectadas por la presencia de NAs en los datos
* La ausencia de un dato puede significar:
  + Una falla tecnica al obtener los datos.
  + Un error humano.
  + Dificultades al medir la variable. 
  + Una ausencia real y justificada en los datos. Por ejemplo, en los resultados de un item no obligatorio de una encuesta. 

Para cada caso debemos de tener un plan para resolver la falta de informacion. Por eso debemos saber que hacer al encontrar NA en nuestros datos.

#### 1. Entender su naturaleza

```{r}
vis_miss(df_rrhh)
```

Con esta distribucion, se pueden notar 2 cosas. 

* Hay datos ausentes esparcidos por toda la data de manera aleatorea
* La columna term_date tiene muchos datos ausentes (66.5%)

Que la columna que representa la fecha de terminacion de contrato de un empleado tenga muchos NA no es un misterio. Simplemente quienes siguen activos no tienen una fecha de terminacion. Eso lo podemos comprobar:

Vamos a observar la columna term_date junto con hire_date y employment_status:
```{r}
df_rrhh %>% 
  select(employment_status, hire_date, term_date) %>% 
  head(10)
```

Ahora vamos a contar la cantidad de datos ausentes por employment_status
```{r}
df_rrhh %>% 
  select(employment_status, term_date) %>% 
  group_by(employment_status) %>% 
  summarise(n_na = sum(is.na(term_date)))
```
Con esto podemos comprobar que hay 204 personas actualmente laborando y por tanto su term_date es NA. Entonces estos Na no se deben eliminar porque son congruentes con la realidad de los datos. 

**sum(is.na(variable))** es la forma que tenemos para contar la cantidad de NA. Funciona porque TRUE = 1 y la funcion sum() suma los TRUE que arroja is.na()

si aplicamos: 
```{r}
sum(is.na(df_rrhh)) # Obtenemos el numero total de NA en la data
```
Utilizamos esos dos numeros y 
```{r}
341 - 204
```
137 NA que deberiamos eliminar

Tambien puede ser util saber la cantidad de NA por columna, porque al eliminar NA en realidad eliminamos las filas o observaciones que los contienen.

Usaremos **sapply** una funcion que sirve para ejecutar funciones en todos los elementos de un vector. Cuando lo usamos en un dataframe, ejecuta una funcion por columnas para cada elemento de ellas. Lo util para este caso es que  devuelve un vector con los nombres de la columna y cuantos NA tiene.

Tambien usaremos **function(x)** es una funcion para crear funciones. En este caso particular he creado una funciona anonima (porque no tiene nombre) que sirve para contar los na de un vector. "x" representa los argumentos de la funcion. En este caso X es una columna del dataframe ya que esta dentro del sapply y esta funcion divide cada una de las columnas en vectores independientes y luego les aplica la funcion que le indiquemos

```{r}
na_columnas <- sapply(df_rrhh, function(x) {sum(is.na(x))}) # vector con cuantos NA hay por col

na_columnas <- sort(na_columnas, decreasing = FALSE) # arreglamos de forma ascendente

na_columnas_df <- data.frame(na_columnas) # lo convertimos en un dataframe
tail(na_columnas_df, 10) # obtenemos las columnas con mas datos ausentes
```

Esto nos da una idea de cuantas filas hay que eliminar de nuestros datos. 

#### 2. Elimanar los datos ausentes

si aplicamos la funcion **na.omit( <df> )** eliminaremos todos los datos ausentes y solo se quedaran en nuestra data aquellas filas que no tengan ningun NA.

Sin embargo no podemos aplicar esa solucion a los datos porque eliminariamos mas 60% de los datos. 

Hay que hacer una solucion mas inteligente.

Con dplyr la forma de eliminar datos NA es usando un *filtrado inverso*: 

- **filter** para filtrar lo datos
- **!** para negar el resultado (si es TRUE, sera FALSE y viceversa)
- **is.na()** para encontrar los NA

>  filter(!is.na(variable)

Es la forma de filtrar los datos que **NO** son NA. 

```{r}
# Visualizamos que la solucion elimino los NA deseados
df_rrhh %>% 
  filter(!is.na(po_id), 
         !is.na(absences),
         !is.na(manager_name),
         !is.na(last_perf_rev_date),
         !is.na(emp_satisfaction), 
         !is.na(marital_status),
         !is.na(citizenship)) %>% 
  vis_miss()

```

```{r}
# Asignamos el nuevo dataset a una nuevo objeto

sin_na_df_rrhh <- df_rrhh %>% 
  filter(!is.na(po_id), 
         !is.na(absences),
         !is.na(manager_name),
         !is.na(last_perf_rev_date),
         !is.na(emp_satisfaction), 
         !is.na(marital_status),
         !is.na(citizenship))
```

Con esto tenemos un dataset sin NA. Tambien podemos comprobar que la columna term_date este bien de esta forma:

```{r}
sin_na_df_rrhh %>% 
  select(employment_status, term_date) %>% 
  group_by(employment_status) %>% 
  summarise(n_na = sum(is.na(term_date)))
```


### Observar los valores de cada columna

Necesitamos saber si los datos de nuestras columnas son congruentes y que no haya datos extranos.

Eso lo podemos hacer de varias formas, pero les dare un par que son sencillas

#### Variables characters

Hay 2 columnas de tipo character que tienen datos extraños, les muestro 1 y el resto se las dejo a ustedes:

- po_name: es la mas dificil de identificar por la cantidad de categorias que tiene.
- ?

Forma de revisar las categorias y los rangos de los datos:
```{r}
prueba <- sapply(sin_na_df_rrhh, function(x) {
  if(is.numeric(x)) {
    range(x)
  } else {
    unique(x)
  }
})
```

```{r}
prueba$po_name
```


```{r}
fact_sin_na_rrhh <- sin_na_df_rrhh %>% 
  mutate(across(c(4, 5, 7, 8, 9, 10, 11, 14, 15, 16, 19, 20), as.factor))
```

Lueg, pueden ver las categorias que tienen estas variables, y su distribucion. El unico problema es que si manejas muchas categorias para una variable, estas no se te muestran. Pero puedes hacer summary() de variables individuales

```{r}
summary(fact_sin_na_rrhh)
```

Tambien es valido revisar las categorias individualmente. Les adelanto que hay 4 columnas que tienen datos extraños, les muestro 1 y el resto se las dejo a ustedes:

- po_name: es la mas dificil de identificar por la cantidad de categorias que tiene.
- ?
- ?
- ?

```{r}
summary(fact_sin_na_rrhh$po_name)
```
Como cambiarla? Tendriamos que ver si es posible recuperar su informacion con respecto a otras variables, o la informacion que nos suministra la data. En este caso particular podriamos

- Eliminar los datos que contengan la categoria
- Cambiarla a una categoria que ya exista (si es posible)
- Crear una nueva categoria 

```{r}
# Usaremos if_else para cambiar la categoria

fact_sin_na_rrhh %>%
  select(po_name) %>% 
  mutate(po_name = if_else(po_name == "pasante subpagado", "intern", po_name))
```


#### Revisar datos numericos 
```{r}

```



